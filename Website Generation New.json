{
  "id": "18308921-5f41-4e1c-949f-22c2cb0c8902",
  "data": {
    "nodes": [
      {
        "id": "ChatOutput-umf4t",
        "type": "genericNode",
        "position": {
          "x": 1293.497698762176,
          "y": 1969.017897442648
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-umf4t"
        },
        "selected": false,
        "width": 320,
        "height": 234,
        "positionAbsolute": {
          "x": 1293.497698762176,
          "y": 1969.017897442648
        },
        "dragging": false
      },
      {
        "id": "ChatInput-QvJmC",
        "type": "genericNode",
        "position": {
          "x": -646.1547048745223,
          "y": 966.3703861070824
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "a simple dashboard",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatInput",
          "id": "ChatInput-QvJmC"
        },
        "selected": true,
        "width": 320,
        "height": 234,
        "positionAbsolute": {
          "x": -646.1547048745223,
          "y": 966.3703861070824
        },
        "dragging": false
      },
      {
        "id": "Prompt-cFK4G",
        "type": "genericNode",
        "position": {
          "x": -251.90071572649373,
          "y": 733.0526742530348
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Your task is to design a new React component for a web app, according to the user's request,If you judge it is relevant to do so, you can specify pre-made library components to use in the task, You can also specify the use of icons if you see that the user's request requires it.\n\nMultiple components can be used while creating a new component in order to help you do a better design job, faster.\n\nAVAILABLE COMPONENTS:\n\n{available}\n\nUser Query : {query}\n\nDesign the new React web component task for the user as the creative genius you are",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "available": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "available",
                "display_name": "available",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "User Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "available",
                "query"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-cFK4G"
        },
        "selected": false,
        "width": 320,
        "height": 433,
        "positionAbsolute": {
          "x": -251.90071572649373,
          "y": 733.0526742530348
        },
        "dragging": false
      },
      {
        "id": "Pinecone-R8c3L",
        "type": "genericNode",
        "position": {
          "x": -1802.7420866782122,
          "y": 1312.0350348667705
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import numpy as np\nfrom langchain_pinecone import Pinecone\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import DataInput, DropdownInput, HandleInput, IntInput, MultilineInput, SecretStrInput, StrInput\nfrom langflow.schema import Data\n\n\nclass PineconeVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Pinecone\"\n    description = \"Pinecone Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/\"\n    name = \"Pinecone\"\n    icon = \"Pinecone\"\n    inputs = [\n        StrInput(name=\"index_name\", display_name=\"Index Name\", required=True),\n        StrInput(name=\"namespace\", display_name=\"Namespace\", info=\"Namespace for the index.\"),\n        DropdownInput(\n            name=\"distance_strategy\",\n            display_name=\"Distance Strategy\",\n            options=[\"Cosine\", \"Euclidean\", \"Dot Product\"],\n            value=\"Cosine\",\n            advanced=True,\n        ),\n        SecretStrInput(name=\"pinecone_api_key\", display_name=\"Pinecone API Key\", required=True),\n        StrInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key in the record to use as text.\",\n            value=\"text\",\n            advanced=True,\n        ),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self) -> Pinecone:\n        \"\"\"Build and return a Pinecone vector store instance.\"\"\"\n        try:\n            from langchain_pinecone._utilities import DistanceStrategy\n\n            # Wrap the embedding model to ensure float32 output\n            wrapped_embeddings = Float32Embeddings(self.embedding)\n\n            # Convert distance strategy\n            distance_strategy = self.distance_strategy.replace(\" \", \"_\").upper()\n            distance_strategy = DistanceStrategy[distance_strategy]\n\n            # Initialize Pinecone instance with wrapped embeddings\n            pinecone = Pinecone(\n                index_name=self.index_name,\n                embedding=wrapped_embeddings,  # Use wrapped embeddings\n                text_key=self.text_key,\n                namespace=self.namespace,\n                distance_strategy=distance_strategy,\n                pinecone_api_key=self.pinecone_api_key,\n            )\n        except Exception as e:\n            error_msg = \"Error building Pinecone vector store\"\n            raise ValueError(error_msg) from e\n        else:\n            # Process documents if any\n            documents = []\n            if self.ingest_data:\n                for doc in self.ingest_data:\n                    if isinstance(doc, Data):\n                        documents.append(doc.to_lc_document())\n                    else:\n                        documents.append(doc)\n\n                if documents:\n                    pinecone.add_documents(documents)\n\n            return pinecone\n\n    def search_documents(self) -> list[Data]:\n        \"\"\"Search documents in the vector store.\"\"\"\n        try:\n            if not self.search_query or not isinstance(self.search_query, str) or not self.search_query.strip():\n                return []\n\n            vector_store = self.build_vector_store()\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n        except Exception as e:\n            error_msg = \"Error searching documents\"\n            raise ValueError(error_msg) from e\n        else:\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n\n\nclass Float32Embeddings:\n    \"\"\"Wrapper class to ensure float32 embeddings.\"\"\"\n\n    def __init__(self, base_embeddings):\n        self.base_embeddings = base_embeddings\n\n    def embed_documents(self, texts):\n        embeddings = self.base_embeddings.embed_documents(texts)\n        if isinstance(embeddings, np.ndarray):\n            return [[self._force_float32(x) for x in vec] for vec in embeddings]\n        return [[self._force_float32(x) for x in vec] for vec in embeddings]\n\n    def embed_query(self, text):\n        embedding = self.base_embeddings.embed_query(text)\n        if isinstance(embedding, np.ndarray):\n            return [self._force_float32(x) for x in embedding]\n        return [self._force_float32(x) for x in embedding]\n\n    def _force_float32(self, value):\n        \"\"\"Convert any numeric type to Python float.\"\"\"\n        return float(np.float32(value))\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "distance_strategy": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Cosine",
                  "Euclidean",
                  "Dot Product"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "distance_strategy",
                "value": "Cosine",
                "display_name": "Distance Strategy",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "index_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "index_name",
                "value": "shadcn",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "namespace": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "namespace",
                "value": "ns1",
                "display_name": "Namespace",
                "advanced": false,
                "dynamic": false,
                "info": "Namespace for the index.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "pinecone_api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "pinecone_api_key",
                "value": "",
                "display_name": "Pinecone API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "search_query": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "text_key": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key",
                "value": "text",
                "display_name": "Text Key",
                "advanced": true,
                "dynamic": false,
                "info": "Key in the record to use as text.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Pinecone Vector Store with search capabilities",
            "icon": "Pinecone",
            "base_classes": [
              "Data",
              "Retriever"
            ],
            "display_name": "Pinecone",
            "documentation": "https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Retriever"
                ],
                "selected": "Retriever",
                "name": "base_retriever",
                "display_name": "Retriever",
                "method": "build_base_retriever",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "index_name",
                  "pinecone_api_key"
                ]
              }
            ],
            "field_order": [
              "index_name",
              "namespace",
              "distance_strategy",
              "pinecone_api_key",
              "text_key",
              "search_query",
              "ingest_data",
              "embedding",
              "number_of_results"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Pinecone",
          "id": "Pinecone-R8c3L"
        },
        "selected": false,
        "width": 320,
        "height": 640,
        "dragging": false,
        "positionAbsolute": {
          "x": -1802.7420866782122,
          "y": 1312.0350348667705
        }
      },
      {
        "id": "OpenAIEmbeddings-PTCbo",
        "type": "genericNode",
        "position": {
          "x": -2209.5836843234747,
          "y": 1710.671778049381
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-small",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_version": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "embeddings",
            "key": "OpenAIEmbeddings",
            "lf_version": "1.1.1"
          },
          "type": "OpenAIEmbeddings",
          "id": "OpenAIEmbeddings-PTCbo"
        },
        "selected": false,
        "width": 320,
        "height": 322,
        "positionAbsolute": {
          "x": -2209.5836843234747,
          "y": 1710.671778049381
        },
        "dragging": false
      },
      {
        "id": "JSONCurlyBraceFormatter-5LKIL",
        "type": "genericNode",
        "position": {
          "x": -644.2126307514785,
          "y": 675.6031250152088
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import os\nimport json\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\nclass JSONCurlyBraceFormatter(Component):\n    display_name = \"JSON Curly Brace Formatter\"\n    description = \"Reads a JSON file with a list of dictionaries and returns the JSON with double curly braces around each dictionary.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"brace\"\n    name = \"JSONCurlyBraceFormatter\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Formatted JSON\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> str:\n        file_path = self.path\n        \n        if not file_path:\n            raise ValueError(\"File path cannot be empty.\")\n        \n        if not os.path.isfile(file_path):\n            raise FileNotFoundError(f\"The path '{file_path}' is not a valid file.\")\n        \n        if not file_path.endswith(\".json\"):\n            raise ValueError(f\"The file '{file_path}' is not a JSON file.\")\n        \n        try:\n            with open(file_path, 'r', encoding='utf-8') as file:\n                json_data = json.load(file)\n\n            if not isinstance(json_data, list) or not all(isinstance(item, dict) for item in json_data):\n                raise ValueError(\"The JSON file does not contain a list of dictionaries.\")\n\n            formatted_data = [\n                f\"{{ {json.dumps(item, ensure_ascii=False)} }}\"\n                for item in json_data\n            ]\n\n            formatted_output = \"[\\n    \" + \",\\n    \".join(formatted_data) + \"\\n]\"\n        \n        except json.JSONDecodeError as e:\n            raise ValueError(f\"Error decoding JSON file: {e}\")\n\n        return formatted_output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "path": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "components.json",
                "display_name": "Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Path to the directory to load files from.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Reads a JSON file with a list of dictionaries and returns the JSON with double curly braces around each dictionary.",
            "icon": "brace",
            "base_classes": [
              "Text"
            ],
            "display_name": "JSON Reader",
            "documentation": "http://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Text"
                ],
                "selected": "Text",
                "name": "output",
                "display_name": "Formatted JSON",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "path"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "JSONCurlyBraceFormatter",
          "id": "JSONCurlyBraceFormatter-5LKIL"
        },
        "selected": false,
        "width": 320,
        "height": 274,
        "dragging": false,
        "positionAbsolute": {
          "x": -644.2126307514785,
          "y": 675.6031250152088
        }
      },
      {
        "id": "OpenAIModel-M9jS6",
        "type": "genericNode",
        "position": {
          "x": 107.77121855406688,
          "y": 878.5191961416315
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": true,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "load_from_db": false
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": [
                  {
                    "": ""
                  }
                ],
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput",
                "load_from_db": false
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "You are an expert React component designer tasked with creating a detailed JSON schema for a new web application component.   Your goal is to precisely translate user requirements into a structured JSON format that captures all relevant design specifications.    IMPORTANT RULES:   1. Always respond in a valid JSON format  2. Strictly follow the schema structure  3. ONLY use components from the provided list below - do not suggest components that aren't in this list 4. Be creative and practical in component design  5. for the new_component_description, write your own more detailed description for the component the user has requested    OUTPUT SCHEMA:  Create a JSON response following this schema:  {{    \t\"new_component_name\": \"string\",    \t\"new_component_description\": \"string\",     \t\"use_components\":  \t[      \t\t{{        \t\t\t\"component_name\": \"string\", \t\t\t“filename”: “string,  \t\t\t\"component_usage_reason\": \"string\"      \t\t}} \t] , \t\"required_images\":  \t[  \t\t{{  \t\t\t\"image_purpose\": “string”, \t\t\t\t \t\t\t\"generation_prompt\": “string”,  \t\t\t\"target_component\": “string”, \t\t\t\"suggested_dimensions\":  \t\t\t{{  \t\t\t\t\"width\": “number”, \t\t\t\t“height\": “number”,  \t\t\t}} \t\t}} \t] }}  IMPORTANT: Your response must ONLY include components that exist in the AVAILABLE COMPONENTS list provided above. Do not suggest or include any components that are not explicitly listed.",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "OpenAIModel",
          "id": "OpenAIModel-M9jS6"
        },
        "selected": false,
        "width": 320,
        "height": 674,
        "dragging": false,
        "positionAbsolute": {
          "x": 107.77121855406688,
          "y": 878.5191961416315
        }
      },
      {
        "id": "OpenAIEmbeddings-EYJyx",
        "type": "genericNode",
        "position": {
          "x": -1051.4030114216046,
          "y": 2246.5594143308113
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-small",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_version": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "embeddings",
            "key": "OpenAIEmbeddings",
            "lf_version": "1.1.1"
          },
          "type": "OpenAIEmbeddings",
          "id": "OpenAIEmbeddings-EYJyx"
        },
        "selected": false,
        "width": 320,
        "height": 322,
        "positionAbsolute": {
          "x": -1051.4030114216046,
          "y": 2246.5594143308113
        },
        "dragging": false
      },
      {
        "id": "PineconeSearch-XLDaU",
        "type": "genericNode",
        "position": {
          "x": -392.08582515632963,
          "y": 1800.9620596379355
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.inputs import DropdownInput, HandleInput\nfrom langchain_pinecone.vectorstores import Pinecone\n\n\nclass PineconeSearchComponent(Component):\n    \"\"\"Component to search Pinecone vector store and return documents.\"\"\"\n    \n    display_name = \"Pinecone Search\"\n    description = \"Searches Pinecone vector store for documents using filename as filter\"\n    icon = \"Pinecone\"\n    name = \"PineconeSearch\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"query\",\n            display_name=\"Query\",\n            info=\"The filename to search for in Pinecone\",\n        ),\n        HandleInput(\n            name=\"embedding\", \n            display_name=\"Embedding\", \n            input_types=[\"Embeddings\"]\n        ),\n        MessageTextInput(\n            name=\"pinecone_api_key\",\n            display_name=\"Pinecone API Key\",\n            required=True,\n            info=\"Your Pinecone API Key\",\n        ),\n        MessageTextInput(\n            name=\"index_name\",\n            display_name=\"Index Name\",\n            required=True,\n            info=\"The name of your Pinecone index\",\n            value=\"shadcn\",\n        ),\n        MessageTextInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"The namespace to use in the Pinecone index\",\n            value=\"ns1\",\n        ),\n        DropdownInput(\n            name=\"distance_strategy\",\n            display_name=\"Distance Strategy\",\n            info=\"The distance strategy for similarity search\",\n            options=[\"cosine\", \"euclidean\", \"dot_product\"],\n            value=\"cosine\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n        Output(\n            display_name=\"Pinecone Callable\",\n            name=\"Pinecone Callable\",\n            method=\"get_pinecone_callable\",\n        ),\n    ]\n\n    def build_output(self, query: str = None) -> Data:\n        \"\"\"Search Pinecone for document based on filename.\"\"\"\n        if query: self.query = query\n        try:\n            vector_store = Pinecone(\n                index_name=self.index_name,\n                embedding=self.embedding,\n                namespace=self.namespace,\n                distance_strategy=self.distance_strategy,\n                pinecone_api_key=self.pinecone_api_key,\n            )\n\n            dummy_query = \" \"\n            filter_dict = {\"filename\": {\"$eq\": query}}\n            \n            docs = vector_store.similarity_search(\n                query=dummy_query,\n                k=1,\n                filter=filter_dict\n            )\n            \n            if docs and len(docs) > 0:\n                doc = docs[0]\n                \n                if hasattr(doc, 'page_content'):\n                    return doc.page_content\n                elif isinstance(doc, dict):\n                    return doc.get('content', doc.get('page_content', 'No content found.'))\n            \n        except Exception as e:\n            print(f\"Pinecone query error: {str(e)}\")\n            return f\"Error querying Pinecone: {str(e)}\"\n\n            \n    def get_pinecone_callable(self) -> Callable:\n        return self.build_output",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "distance_strategy": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "cosine",
                  "euclidean",
                  "dot_product"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "distance_strategy",
                "value": "cosine",
                "display_name": "Distance Strategy",
                "advanced": false,
                "dynamic": false,
                "info": "The distance strategy for similarity search",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "index_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "index_name",
                "value": "shadcn",
                "display_name": "Index Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of your Pinecone index",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "namespace": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "namespace",
                "value": "ns1",
                "display_name": "Namespace",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The namespace to use in the Pinecone index",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "pinecone_api_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "pinecone_api_key",
                "value": "PINECONE_API_KEY",
                "display_name": "Pinecone API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Pinecone API Key",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "query": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "query",
                "value": "",
                "display_name": "Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The filename to search for in Pinecone",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Searches Pinecone vector store for documents using filename as filter",
            "icon": "Pinecone",
            "base_classes": [
              "Callable",
              "Data"
            ],
            "display_name": "PineCone Search",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Callable"
                ],
                "selected": "Callable",
                "name": "Pinecone Callable",
                "display_name": "Pinecone Callable",
                "method": "get_pinecone_callable",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "query",
              "embedding",
              "pinecone_api_key",
              "index_name",
              "namespace",
              "distance_strategy"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "PineconeSearch",
          "id": "PineconeSearch-XLDaU"
        },
        "selected": false,
        "width": 320,
        "height": 698,
        "positionAbsolute": {
          "x": -392.08582515632963,
          "y": 1800.9620596379355
        },
        "dragging": false
      },
      {
        "id": "OpenAI-Dcxkq",
        "type": "genericNode",
        "position": {
          "x": 901.9949003259946,
          "y": 1751.1837999583443
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "messages": {
                "type": "List[Dict]",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "messages",
                "display_name": "Messages",
                "advanced": false,
                "input_types": [
                  "Dict"
                ],
                "dynamic": false,
                "info": "List of messages with roles (system/user/assistant) and content",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output, DropdownInput, SecretStrInput\nfrom langchain_openai import ChatOpenAI\nfrom langchain.schema import HumanMessage, SystemMessage, AIMessage\nfrom langflow.template import Input, Output\n\n\nclass OpenAI(Component):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAI\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            required=True,\n            info=\"Your OpenAI API Key.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=[\"gpt-4o-mini\"],\n            value=\"gpt-4o-mini\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        Input(\n            name=\"messages\",\n            display_name=\"Messages\",\n            info=\"List of messages with roles (system/user/assistant) and content\",\n            field_type=\"List[Dict]\",\n            input_types=[\"Dict\"],\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Response\",\n            name=\"response\",\n            method=\"build_model\",\n        ),\n    ]\n\n    def build_model(self) -> Message:\n        messages =  self.messages\n        response = self.query(messages)\n\n        return response\n\n    def query(self, messages: List[Dict[str, str]]) -> str:\n        \"\"\"Call OpenAI API with the prepared context.\"\"\"\n\n        langchain_messages = []\n        for msg in messages:\n            if msg[\"role\"] == \"system\":\n                langchain_messages.append(SystemMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"user\":\n                langchain_messages.append(HumanMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"assistant\":\n                langchain_messages.append(AIMessage(content=msg[\"content\"]))\n\n        chat = ChatOpenAI(\n            model_name=self.model_name,\n            temperature=self.temperature,\n            api_key=self.openai_api_key,\n        )\n\n        response = chat(langchain_messages)\n        return response.content\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your OpenAI API Key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "openai_api_key",
              "model_name",
              "temperature",
              "messages"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "OpenAI",
          "id": "OpenAI-Dcxkq"
        },
        "selected": false,
        "width": 320,
        "height": 457,
        "positionAbsolute": {
          "x": 901.9949003259946,
          "y": 1751.1837999583443
        },
        "dragging": false
      },
      {
        "id": "StableDiffusion-PjO0G",
        "type": "genericNode",
        "position": {
          "x": -1052.7048232924224,
          "y": 938.3889603314897
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "api_token_1": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_token_1",
                "value": "",
                "display_name": "Primary HuggingFace API Token",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Primary HuggingFace Access Token for authentication",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "api_token_2": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_token_2",
                "value": "",
                "display_name": "Fallback HuggingFace API Token",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Secondary HuggingFace Access Token for fallback",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "https://api-inference.huggingface.co/models/stabilityai",
                "display_name": "Base URL",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Base API endpoint URL for Stable Diffusion",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output, DropdownInput, SecretStrInput, IntInput\nimport requests\nimport base64\nimport io\n\nclass StableDiffusion(Component):\n    display_name = \"StableDiffusion\"\n    description = \"StableDiffusion Image Generator\"\n    icon = \"image\"\n    name = \"StableDiffusion\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"api_token_1\",\n            display_name=\"Primary HuggingFace API Token\",\n            info=\"Primary HuggingFace Access Token for authentication\",\n            password=True,\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_token_2\",\n            display_name=\"Fallback HuggingFace API Token\",\n            info=\"Secondary HuggingFace Access Token for fallback\",\n            password=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            info=\"Base API endpoint URL for Stable Diffusion\",\n            value=\"https://api-inference.huggingface.co/models/stabilityai\",\n            advanced=True,\n            required=True,\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"Select the Stable Diffusion model to use\",\n            options=[\n                \"stable-diffusion-3.5-large\",\n                \"stable-diffusion-3.5-large-turbo\",\n                \"stable-diffusion-3.5-medium\",\n                \"stable-diffusion-3-medium\",\n            ],\n            value=\"stable-diffusion-3.5-large\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"prompt\",\n            display_name=\"Prompt\",\n            info=\"Text input to generate an image\",\n            value=\"\",\n        ),\n        IntInput(\n            name=\"width\",\n            display_name=\"Width\",\n            value=1024,\n            info=\"width divisible by 16\",\n        ),\n        IntInput(\n            name=\"height\",\n            display_name=\"Height\",\n            value=1024,\n            info=\"height divisible by 16\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Base64 encoded Image String\",\n            name=\"base64_image\",\n            method=\"generate_image\",\n        ),\n        Output(\n            display_name=\"ImgGen Callable\",\n            name=\"ImgGen Callable\",\n            method=\"get_imaggen_callable\",\n        ),\n    ]\n\n    def generate_image(\n        self,\n        prompt: str = None,\n        width: int = None,\n        height: int = None,\n    ) -> str:\n        \"\"\"\n        Generate an image based on the provided prompt.\n        Converts the API response content into a Base64-encoded string.\n        \n        :param prompt: Optional text prompt for image generation.\n        :return: Base64-encoded image string.\n        \"\"\"\n\n        if prompt:\n            self.prompt = prompt\n        if width:\n            self.width = width\n        if height:\n            self.height = height\n\n        response = self.query(api_token=self.api_token_1)\n        if response.status_code != 200 and self.api_token_2:\n            print(\"Primary token failed, trying fallback token...\")\n            response = self.query(api_token=self.api_token_2)\n\n        if response.status_code == 200:\n            image_base64 = base64.b64encode(io.BytesIO(response.content).getvalue()).decode(\"utf-8\")\n            return image_base64\n        else:\n\n            raise ValueError(f\"Failed to generate image. API returned status code {response.status_code}: {response.text}\")\n\n    def query(self, api_token: str) -> requests.Response:\n        \"\"\"\n        Send a request to the Stable Diffusion API to generate an image.\n        \n        :param api_token: API token for authorization.\n        :return: The API response containing the generated image.\n        \"\"\"\n        \n        prompt = self.prompt\n        model = self.model\n        base_url = self.base_url\n        width = self.width\n        height = self.height\n\n        API_URL = f\"{base_url}/{model}\"\n\n        headers = {\"Authorization\": f\"Bearer {api_token}\"}\n\n        payload = {\n            \"inputs\": prompt,\n            \"parameters\": {\n                \"width\": width,\n                \"height\": height,\n            }\n        }\n\n        response = requests.post(API_URL, headers=headers, json=payload)\n\n        return response\n\n    def get_imaggen_callable(self) -> Callable:\n        \"\"\"\n        Return the generate_image method as a callable for external usage.\n        \n        :return: Callable function to generate an image.\n        \"\"\"\n        return self.generate_image\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "height": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "height",
                "value": 1024,
                "display_name": "Height",
                "advanced": false,
                "dynamic": false,
                "info": "height divisible by 16",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "stable-diffusion-3.5-large",
                  "stable-diffusion-3.5-large-turbo",
                  "stable-diffusion-3.5-medium",
                  "stable-diffusion-3-medium"
                ],
                "combobox": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "stable-diffusion-3.5-large",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "Select the Stable Diffusion model to use",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "prompt": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "prompt",
                "value": "",
                "display_name": "Prompt",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text input to generate an image",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "width": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "width",
                "value": 1024,
                "display_name": "Width",
                "advanced": false,
                "dynamic": false,
                "info": "width divisible by 16",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "StableDiffusion Image Generator",
            "icon": "image",
            "base_classes": [
              "Callable",
              "Text"
            ],
            "display_name": "StableDiffusion",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Text"
                ],
                "selected": "Text",
                "name": "base64_image",
                "display_name": "Base64 encoded Image String",
                "method": "generate_image",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Callable"
                ],
                "selected": "Callable",
                "name": "ImgGen Callable",
                "display_name": "ImgGen Callable",
                "method": "get_imaggen_callable",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "api_token_1",
              "api_token_2",
              "base_url",
              "model",
              "prompt",
              "width",
              "height"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "StableDiffusion",
          "id": "StableDiffusion-PjO0G"
        },
        "selected": false,
        "width": 320,
        "height": 718,
        "positionAbsolute": {
          "x": -1052.7048232924224,
          "y": 938.3889603314897
        },
        "dragging": false
      },
      {
        "id": "Agent-3OxXM",
        "type": "genericNode",
        "position": {
          "x": 517.1877960371821,
          "y": 1699.8730474285405
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "Image_callable": {
                "type": "function",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "Image_callable",
                "display_name": "Image Generation Callable",
                "advanced": false,
                "input_types": [
                  "Callable"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "Pinecone_callable": {
                "type": "function",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "Pinecone_callable",
                "display_name": "Pinecone Callable",
                "advanced": false,
                "input_types": [
                  "Callable"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import json\nimport random\nimport string\nfrom typing import List, Dict, Any\nfrom langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.template import Input\n\nclass ValidateLLMResponseComponent(Component):\n    display_name = \"Agent\"\n    description = \"Generates the Component code with image integration for the user Query.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"bot\"\n    name = \"Agent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"llm_response\",\n            display_name=\"LLM Response\",\n            info=\"JSON response from the LLM to validate.\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"user_query\",\n            display_name=\"User Query\",\n            info=\"User's query or context (optional).\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n            required=True,\n        ),\n        Input(\n            name=\"Pinecone_callable\",\n            display_name=\"Pinecone Callable\",\n            field_type=\"function\",\n            input_types=[\"Callable\"],\n            required=True,\n        ),\n        Input(\n            name=\"Image_callable\",\n            display_name=\"Image Generation Callable\",\n            field_type=\"function\",\n            input_types=[\"Callable\"],\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Generated Code\",\n            name=\"generated_code\",\n            method=\"build_output\",\n        ),\n    ]\n    \n    def validate_and_adjust_dimensions(self,dimensions):\n        \"\"\"\n        Validates and adjusts dimensions to ensure they are less than 1024 and \n        divisible by 16.\n    \n        :param dimensions: A dictionary containing 'width' and 'height'.\n        :return: None. Modifies the dimensions dictionary in place.\n        \"\"\"\n        def reduce_to_nearest_int_divisible_by_16(number):\n            number = int(number)\n            adjusted_number = number - (number % 16)\n            return min(adjusted_number, 1024 - (1024 % 16))\n    \n        dimensions['width'] = reduce_to_nearest_int_divisible_by_16(dimensions['width'])\n        dimensions['height'] = reduce_to_nearest_int_divisible_by_16(dimensions['height'])\n\n\n    def prepare_openai_context(self, results, user_query) -> List[Dict[str, str]]:\n        \"\"\"Prepare the context messages for OpenAI API in the required format.\"\"\"\n        context_messages = [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"You are an expert at writing React components.\\n\"\n                    \"Your task is to write a new React component for a web app, according to the provided task details.\\n\"\n                    \"The React component you write can make use of Tailwind classes for styling.\\n\"\n                    \"If you judge it is relevant to do so, you can use library components and icons.\\n\\n\"\n                    \"You will write the full React component code, which should include all imports.\"\n                    \"Your generated code will be directly written to a .tsx React component file and used in production.\"\n                )\n            }\n        ]\n\n        total_components = len(results[\"components\"])\n        for idx, component_info in enumerate(results[\"pinecone_context\"]):\n            component_name = next(\n                (comp[\"name\"] for comp in results[\"components\"] \n                 if comp[\"filename\"] == component_info[\"filename\"]), \n                \"Unknown Component\"\n            )\n            component_usage = next(\n                (comp[\"reason\"] for comp in results[\"components\"] \n                 if comp[\"filename\"] == component_info[\"filename\"]), \n                \"No usage specified\"\n            )\n\n            context_message = {\n                \"role\": \"user\",\n                \"content\": (\n                    f\"Library components can be used while making the new React component\\n\\n\"\n                    f\"Suggested library component ({idx + 1}/{total_components}): {component_name}\\n\"\n                    f\"Suggested usage: {component_usage}\\n\\n\"\n                    f\"Component details and examples:\\n{component_info['context']}\\n\\n---\\n\"\n                )\n            }\n            context_messages.append(context_message)\n\n        if results.get(\"generated_images\"):\n            images_context = {\n                \"role\": \"user\",\n                \"content\": (\n                    \"The following images have been generated and are available for use in the component:\\n\\n\"\n                    + \"\\n\".join([\n                        f\"- Image for {img['target_component']} with dimensions {img['dimensions']['width']}x{img['dimensions']['height']}: {img['link']}\"\n                        for img in results[\"generated_images\"]\n                    ])\n                    + \"\\n\\nPlease use these images in the appropriate places in the component.\\n---\\n\"\n                )\n            }\n            context_messages.append(images_context)\n\n        final_user_message = {\n            \"role\": \"user\",\n            \"content\": (\n                f\"- COMPONENT NAME: {results['name']}\\n\\n\"\n                f\"- COMPONENT DESCRIPTION:\\n\"\n                \"```\\n\"\n                f\"{user_query}\\n\"\n                \"```\\n\\n\"\n                f\"- additional component suggestions:\\n\"\n                \"```\\n\"\n                f\"{results['description']['llm']}\\n\"\n                \"```\\n\\n\\n\"\n                \"Write the full code for the new React web component, which uses Tailwind classes if needed \"\n                \"(add tailwind dark: classes too if you can; backgrounds in dark: classes should be black), \"\n                \"and optionally, library components and icons, based on the provided design task.\\n\"\n                \"The full code of the new React component that you write will be written directly to a .tsx file \"\n                \"inside the React project. Make sure all necessary imports are done, and that your full code is \"\n                \"enclosed with ```tsx blocks.\\n\"\n                \"Answer with generated code only. DO NOT ADD ANY EXTRA TEXT DESCRIPTION OR COMMENTS BESIDES THE CODE. \"\n                \"Your answer contains code only! component code only!\\n\"\n                \"Important:\\n\"\n                \"- Make sure you import provided components libraries and icons that are provided to you if you use them!\\n\"\n                \"- Tailwind classes should be written directly in the elements class tags (or className in case of React). \"\n                \"DO NOT WRITE ANY CSS OUTSIDE OF CLASSES. DO NOT USE ANY <style> IN THE CODE! CLASSES STYLING ONLY!\\n\"\n                \"- Do not use libraries or imports except what is provided in this task; otherwise it would crash the \"\n                \"component because not installed. Do not import extra libraries besides what is provided above!\\n\"\n                \"- DO NOT HAVE ANY DYNAMIC DATA OR DATA PROPS! Components are meant to be working as is without \"\n                \"supplying any variable to them when importing them! Only write a component that render directly \"\n                \"with placeholders as data, component not supplied with any dynamic data.\\n\"\n                \"- DO NOT HAVE ANY DYNAMIC DATA OR DATA PROPS!\\n\"\n                \"- Only write the code for the component; Do not write extra code to import it! The code will \"\n                \"directly be stored in an individual React .tsx file!\\n\"\n                \"Write the React component code as the creative genius you are - with good ui formatting.\\n\"\n            )\n        }\n        context_messages.append(final_user_message)\n\n        return context_messages\n\n    def build_output(self) -> List[Dict]:\n        llm_response = json.loads(self.llm_response)\n        user_query = self.user_query\n\n        results = {\n            \"name\": f\"{llm_response.get('new_component_name', '')}_{self._generate_random_number(4)}\",\n            \"description\": {\n                \"user\": user_query,\n                \"llm\": llm_response.get(\"new_component_description\", \"\"),\n            },\n            \"components\": [],\n            \"component_filenames\": [],\n            \"pinecone_context\": [],\n        }\n\n        metadata_file_path = self.path\n        try:\n            with open(metadata_file_path, \"r\") as file:\n                component_metadata = json.load(file)\n        except Exception as e:\n            return Data(\n                value={\n                    \"error\": f\"Failed to read or parse metadata file: {str(e)}\",\n                    \"user_query\": user_query,\n                }\n            )\n\n        valid_filenames = {component[\"filename\"] for component in component_metadata}\n\n        try:\n            for component in llm_response.get(\"use_components\", []):\n                filename = component[\"filename\"]\n                if filename in valid_filenames:\n                    context = self.Pinecone_callable(filename)\n                    if context:\n                        results[\"pinecone_context\"].append({\n                            \"filename\": filename,\n                            \"context\": context,\n                        })\n                    results[\"components\"].append({\n                        \"name\": component[\"component_name\"],\n                        \"filename\": filename,\n                        \"reason\": component[\"component_usage_reason\"],\n                    })\n                    results[\"component_filenames\"].append(filename)\n\n            if \"required_images\" in llm_response:\n                image_prompts = llm_response[\"required_images\"]\n                for prompt in image_prompts:\n                    self.validate_and_adjust_dimensions(prompt['suggested_dimensions'])\n                \n                try:\n                    generated_images = self.Image_callable(image_prompts)\n                    results[\"generated_images\"] = generated_images\n                except Exception as e:\n                    results[\"image_generation_error\"] = str(e)\n\n            openai_context = self.prepare_openai_context(results, user_query)\n            results[\"openai_context\"] = openai_context\n\n        except Exception as e:\n            return Data(value={\"error\": f\"Error during validation or processing: {str(e)}\"})\n            \n        return openai_context\n            \n    def _generate_random_number(self, length: int) -> str:\n        \"\"\"Generate a random number with a specified length.\"\"\"\n        return ''.join(random.choices(string.digits, k=length))",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "llm_response": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "llm_response",
                "value": "",
                "display_name": "LLM Response",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "JSON response from the LLM to validate.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "path": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "components.json",
                "display_name": "Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Path to the directory to load files from.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_query": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "User Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "User's query or context (optional).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generates the Component code with image integration for the user Query.",
            "icon": "bot",
            "base_classes": [
              "Dict"
            ],
            "display_name": "Agent",
            "documentation": "http://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Dict"
                ],
                "selected": "Dict",
                "name": "generated_code",
                "display_name": "Generated Code",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "llm_response",
              "user_query",
              "path",
              "Pinecone_callable",
              "Image_callable"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Agent",
          "id": "Agent-3OxXM"
        },
        "selected": false,
        "width": 320,
        "height": 524,
        "dragging": false,
        "positionAbsolute": {
          "x": 517.1877960371821,
          "y": 1699.8730474285405
        }
      },
      {
        "id": "CloudinaryUploader-4IS8Y",
        "type": "genericNode",
        "position": {
          "x": -1054.7925198401833,
          "y": 1676.0311652036196
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "Cloudinary API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Cloudinary API key",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "api_secret": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_secret",
                "value": "",
                "display_name": "Cloudinary API Secret",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Cloudinary API secret",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base64_image": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "base64_image",
                "value": "",
                "display_name": "Base64 Image String",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Base64 encoded string of the image",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "cloud_name": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "cloud_name",
                "value": "",
                "display_name": "Cloudinary Cloud Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Cloudinary account cloud name",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output, SecretStrInput\nimport requests\nimport hashlib\nimport time\n\n\nclass CloudinaryUploader(Component):\n    display_name = \"Cloudinary Uploader\"\n    description = \"Upload images to Cloudinary\"\n    icon = \"cloud-upload\"\n    name = \"CloudinaryUploader\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"cloud_name\",\n            display_name=\"Cloudinary Cloud Name\",\n            info=\"Your Cloudinary account cloud name\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Cloudinary API Key\",\n            info=\"Your Cloudinary API key\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_secret\",\n            display_name=\"Cloudinary API Secret\",\n            info=\"Your Cloudinary API secret\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base64_image\",\n            display_name=\"Base64 Image String\",\n            info=\"Base64 encoded string of the image\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Image URL\",\n            name=\"image_url\",\n            method=\"upload_image\",\n        ),\n        Output(\n            display_name=\"Uploader Callable\",\n            name=\"uploader_callable\",\n            method=\"get_uploader_callable\",\n        ),\n    ]\n\n    def upload_image(\n        self,\n        base64_image: str = None,\n    ) -> str:\n        \"\"\"\n        Uploads a Base64-encoded image to Cloudinary and returns the image URL.\n        \"\"\"\n        try:\n            if base64_image:\n                self.base64_image = base64_image\n\n            timestamp = int(time.time())\n            signature_payload = f\"timestamp={timestamp}{self.api_secret}\"\n            signature = hashlib.sha1(signature_payload.encode(\"utf-8\")).hexdigest()\n            print(\"siganture:::\",signature_payload)\n            url = f\"https://api.cloudinary.com/v1_1/{self.cloud_name}/image/upload\"\n\n            payload = {\n                \"file\": f\"data:image/jpeg;base64,{self.base64_image}\",\n                \"api_key\": self.api_key,\n                \"timestamp\": timestamp,\n                \"signature\": signature,\n            }\n\n            response = requests.post(url, data=payload)\n\n            if response.status_code == 200:\n                return response.json().get(\"secure_url\", \"Could not retrieve image URL\")\n            else:\n                return f\"Error: {response.json()}\"\n\n        except Exception as e:\n            return f\"Error uploading image: {e}\"\n\n    def get_uploader_callable(self) -> Callable:\n        \"\"\"\n        Returns the upload_image function as a callable.\n        \"\"\"\n        return self.upload_image\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Upload images to Cloudinary",
            "icon": "cloud-upload",
            "base_classes": [
              "Callable",
              "Text"
            ],
            "display_name": "ImageUploader",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Text"
                ],
                "selected": "Text",
                "name": "image_url",
                "display_name": "Image URL",
                "method": "upload_image",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Callable"
                ],
                "selected": "Callable",
                "name": "uploader_callable",
                "display_name": "Uploader Callable",
                "method": "get_uploader_callable",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "cloud_name",
              "api_key",
              "api_secret",
              "base64_image"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CloudinaryUploader",
          "id": "CloudinaryUploader-4IS8Y"
        },
        "selected": false,
        "width": 320,
        "height": 547,
        "positionAbsolute": {
          "x": -1054.7925198401833,
          "y": 1676.0311652036196
        },
        "dragging": false
      },
      {
        "id": "ProcessImages-jUkrU",
        "type": "genericNode",
        "position": {
          "x": -405.0044539307728,
          "y": 1406.4485935598082
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "imggen_callable": {
                "type": "function",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "imggen_callable",
                "display_name": "ImgGen Callable",
                "advanced": false,
                "input_types": [
                  "Callable"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "required_images": {
                "type": "List[Dict]",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "required_images",
                "display_name": "Required Images",
                "advanced": false,
                "input_types": [
                  "list"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "uploader_callable": {
                "type": "function",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": false,
                "fileTypes": [],
                "file_path": "",
                "name": "uploader_callable",
                "display_name": "Uploader Callable",
                "advanced": false,
                "input_types": [
                  "Callable"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.template import Input, Output\nfrom langflow.schema import Data\nfrom typing import List, Dict, Any, Callable\nimport json\n\nclass ProcessImages(Component):\n    display_name = \"ProcessImages\"\n    description = \"Handles image generation and uploading for React component creation\"\n    icon = \"image\"\n    name = \"ProcessImages\"\n    \n    inputs = [\n        Input(\n            name=\"imggen_callable\",\n            display_name=\"ImgGen Callable\",\n            field_type=\"function\",\n            input_types=[\"Callable\"],\n            required=True,\n        ),\n        Input(\n            name=\"uploader_callable\",\n            display_name=\"Uploader Callable\",\n            field_type=\"function\",\n            input_types=[\"Callable\"],\n            required=True,\n        ),\n        Input(\n            name=\"required_images\",\n            display_name=\"Required Images\",\n            field_type=\"List[Dict]\",\n            input_types=[\"list\"],\n        ),\n    ]\n    \n    outputs = [\n        Output(\n            name=\"Results Dict\",\n            display_name=\"Results Dict\", \n            method=\"process_images\",\n        ),\n        Output(\n            display_name=\"Process Images Callable\",\n            name=\"Process Images Callable\",\n            method=\"get_process_images_callable\",\n        ),\n    ]\n    \n    def process_images(self,required_images: List[Dict] = None) -> Data:\n        \"\"\"\n        Process image generation requests and return results in required format.\n        \"\"\"\n        if required_images: self.required_images = required_images\n        imggen_callable = self.imggen_callable\n        uploader_callable = self.uploader_callable\n    \n        if isinstance(required_images, str):\n            try:\n                required_images = json.loads(required_images)\n            except json.JSONDecodeError:\n                return Data(data=[{\n                    \"error\": \"Invalid JSON format for required_images\"\n                }])\n    \n        results = []\n    \n        for image_req in required_images:\n            try:\n                prompt = image_req.get(\"generation_prompt\")\n                target = image_req.get(\"target_component\")\n\n                dimensions = image_req.get(\"suggested_dimensions\", {})\n                if not isinstance(dimensions, dict):\n                    dimensions = {}\n\n                if not prompt or not target:\n                    results.append({\n                        \"target_component\": target or \"unknown\",\n                        \"link\": \"Error: Missing required fields\",\n                        \"error\": \"Missing generation_prompt or target_component\"\n                    })\n                    continue\n\n                width = int(dimensions.get(\"width\", 512))\n                height = int(dimensions.get(\"height\", 512))\n\n                enhanced_prompt = prompt\n    \n                base64_image = imggen_callable(\n                    prompt=enhanced_prompt,\n                    width=width,\n                    height=height\n                )\n                \n                if not base64_image:\n                    raise ValueError(\"Image generation failed\")\n    \n                uploaded_url = uploader_callable(base64_image)\n\n                results.append({\n                    \"target_component\": target,\n                    \"link\": uploaded_url,\n                    \"dimensions\": {\n                        \"width\": width,\n                        \"height\": height\n                    },\n                })\n    \n            except Exception as e:\n                results.append({\n                    \"target_component\": image_req.get(\"target_component\", \"unknown\"),\n                    \"link\": f\"Error: {str(e)}\",\n                    \"error\": str(e)\n                })\n    \n        return results\n\n    def get_process_images_callable(self) -> Callable:\n        return self.process_images",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Handles image generation and uploading for React component creation",
            "icon": "image",
            "base_classes": [
              "Callable",
              "Data"
            ],
            "display_name": "Image Generator",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "Results Dict",
                "display_name": "Results Dict",
                "method": "process_images",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Callable"
                ],
                "selected": "Callable",
                "name": "Process Images Callable",
                "display_name": "Process Images Callable",
                "method": "get_process_images_callable",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "imggen_callable",
              "uploader_callable",
              "required_images"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ProcessImages",
          "id": "ProcessImages-jUkrU"
        },
        "selected": false,
        "width": 320,
        "height": 361,
        "positionAbsolute": {
          "x": -405.0044539307728,
          "y": 1406.4485935598082
        },
        "dragging": false
      },
      {
        "id": "Directory-akX5U",
        "type": "genericNode",
        "position": {
          "x": -2213.5852936991537,
          "y": 1278.0136045116103
        },
        "data": {
          "type": "Directory",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List\nimport os\nimport logging  \nfrom langflow.base.data.utils import parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, IntInput, MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n        MessageTextInput(\n            name=\"types\",\n            display_name=\"Types\",\n            info=\"File types to load. Leave empty to load all types.\",\n            is_list=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n    ]\n\n    def load_directory(self) -> List[Data]:\n        path = self.path\n        types = self.types or []  # self.types is already a list due to is_list=True\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n        file_paths = retrieve_file_paths(\n            resolved_path,\n            load_hidden=load_hidden,\n            recursive=recursive,\n            depth=depth\n        )\n\n        if types:\n            file_paths = [fp for fp in file_paths if any(fp.endswith(ext) for ext in types)]\n\n        loaded_data = []\n\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors, max_concurrency)\n        else:\n            loaded_data = [self.process_markdown_file(file_path) for file_path in file_paths]\n        loaded_data = self._docs_to_data(loaded_data) #list(filter(None, loaded_data))\n        self.status = loaded_data\n        return loaded_data  # type: ignore\n        \n    def process_markdown_file(self, file_path: str) -> dict:\n        logging.info(f\"Processing file: {file_path}\")\n        try:\n            with open(file_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            \n            # Store the full filename including the extension\n            filename_with_extension = os.path.basename(file_path)\n            \n            logging.info(f\"Successfully processed {filename_with_extension}\")\n            return {\n                \"filename\": filename_with_extension,  # Store the full filename with extension\n                \"content\": content\n            }\n        except IOError as e:\n            logging.error(f\"Error processing file {file_path}: {str(e)}\")\n            return None\n                \n    def _docs_to_data(self, docs):\n        return [Data(text=doc[\"content\"], data={\"filename\": doc[\"filename\"]}) for doc in docs]\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "depth": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "depth",
                "value": 0,
                "display_name": "Depth",
                "advanced": false,
                "dynamic": false,
                "info": "Depth to search for files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "load_hidden": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "load_hidden",
                "value": false,
                "display_name": "Load Hidden",
                "advanced": true,
                "dynamic": false,
                "info": "If true, hidden files will be loaded.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_concurrency": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_concurrency",
                "value": 2,
                "display_name": "Max Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "Maximum concurrency for loading files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "path": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "md-files",
                "display_name": "Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Path to the directory to load files from.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "recursive": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "recursive",
                "value": false,
                "display_name": "Recursive",
                "advanced": true,
                "dynamic": false,
                "info": "If true, the search will be recursive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "silent_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "types": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "types",
                "value": [
                  ""
                ],
                "display_name": "Types",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "File types to load. Leave empty to load all types.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "use_multithreading": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_multithreading",
                "value": false,
                "display_name": "Use Multithreading",
                "advanced": true,
                "dynamic": false,
                "info": "If true, multithreading will be used.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Recursively load files from a directory.",
            "icon": "folder",
            "base_classes": [
              "Data"
            ],
            "display_name": "Directory",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_directory",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "path",
              "types",
              "depth",
              "max_concurrency",
              "load_hidden",
              "recursive",
              "silent_errors",
              "use_multithreading"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Directory-akX5U"
        },
        "selected": false,
        "width": 320,
        "height": 407,
        "positionAbsolute": {
          "x": -2213.5852936991537,
          "y": 1278.0136045116103
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "OpenAIEmbeddings-PTCbo",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-PTCboœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "Pinecone-R8c3L",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œPinecone-R8c3Lœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "Pinecone-R8c3L",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-PTCbo",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-PTCbo{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-PTCboœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-Pinecone-R8c3L{œfieldNameœ:œembeddingœ,œidœ:œPinecone-R8c3Lœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatInput-QvJmC",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-QvJmCœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-cFK4G",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-cFK4Gœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-cFK4G",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-QvJmC",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-QvJmC{œdataTypeœ:œChatInputœ,œidœ:œChatInput-QvJmCœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-cFK4G{œfieldNameœ:œqueryœ,œidœ:œPrompt-cFK4Gœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-cFK4G",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-cFK4Gœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-M9jS6",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-M9jS6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-M9jS6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-cFK4G",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-cFK4G{œdataTypeœ:œPromptœ,œidœ:œPrompt-cFK4Gœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-M9jS6{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-M9jS6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "JSONCurlyBraceFormatter-5LKIL",
        "sourceHandle": "{œdataTypeœ:œJSONCurlyBraceFormatterœ,œidœ:œJSONCurlyBraceFormatter-5LKILœ,œnameœ:œoutputœ,œoutput_typesœ:[œTextœ]}",
        "target": "Prompt-cFK4G",
        "targetHandle": "{œfieldNameœ:œavailableœ,œidœ:œPrompt-cFK4Gœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "available",
            "id": "Prompt-cFK4G",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "JSONCurlyBraceFormatter",
            "id": "JSONCurlyBraceFormatter-5LKIL",
            "name": "output",
            "output_types": [
              "Text"
            ]
          }
        },
        "id": "reactflow__edge-JSONCurlyBraceFormatter-5LKIL{œdataTypeœ:œJSONCurlyBraceFormatterœ,œidœ:œJSONCurlyBraceFormatter-5LKILœ,œnameœ:œoutputœ,œoutput_typesœ:[œTextœ]}-Prompt-cFK4G{œfieldNameœ:œavailableœ,œidœ:œPrompt-cFK4Gœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIEmbeddings-EYJyx",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-EYJyxœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "PineconeSearch-XLDaU",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œPineconeSearch-XLDaUœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "PineconeSearch-XLDaU",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-EYJyx",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-EYJyx{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-EYJyxœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-PineconeSearch-XLDaU{œfieldNameœ:œembeddingœ,œidœ:œPineconeSearch-XLDaUœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-M9jS6",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-M9jS6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-3OxXM",
        "targetHandle": "{œfieldNameœ:œllm_responseœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm_response",
            "id": "Agent-3OxXM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-M9jS6",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-M9jS6{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-M9jS6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Agent-3OxXM{œfieldNameœ:œllm_responseœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatInput-QvJmC",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-QvJmCœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-3OxXM",
        "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "Agent-3OxXM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-QvJmC",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-QvJmC{œdataTypeœ:œChatInputœ,œidœ:œChatInput-QvJmCœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Agent-3OxXM{œfieldNameœ:œuser_queryœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Agent-3OxXM",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-3OxXMœ,œnameœ:œgenerated_codeœ,œoutput_typesœ:[œDictœ]}",
        "target": "OpenAI-Dcxkq",
        "targetHandle": "{œfieldNameœ:œmessagesœ,œidœ:œOpenAI-Dcxkqœ,œinputTypesœ:[œDictœ],œtypeœ:œList[Dict]œ}",
        "data": {
          "targetHandle": {
            "fieldName": "messages",
            "id": "OpenAI-Dcxkq",
            "inputTypes": [
              "Dict"
            ],
            "type": "List[Dict]"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-3OxXM",
            "name": "generated_code",
            "output_types": [
              "Dict"
            ]
          }
        },
        "id": "reactflow__edge-Agent-3OxXM{œdataTypeœ:œAgentœ,œidœ:œAgent-3OxXMœ,œnameœ:œgenerated_codeœ,œoutput_typesœ:[œDictœ]}-OpenAI-Dcxkq{œfieldNameœ:œmessagesœ,œidœ:œOpenAI-Dcxkqœ,œinputTypesœ:[œDictœ],œtypeœ:œList[Dict]œ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAI-Dcxkq",
        "sourceHandle": "{œdataTypeœ:œOpenAIœ,œidœ:œOpenAI-Dcxkqœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-umf4t",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-umf4tœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-umf4t",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAI",
            "id": "OpenAI-Dcxkq",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAI-Dcxkq{œdataTypeœ:œOpenAIœ,œidœ:œOpenAI-Dcxkqœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-umf4t{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-umf4tœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "PineconeSearch-XLDaU",
        "sourceHandle": "{œdataTypeœ:œPineconeSearchœ,œidœ:œPineconeSearch-XLDaUœ,œnameœ:œPinecone Callableœ,œoutput_typesœ:[œCallableœ]}",
        "target": "Agent-3OxXM",
        "targetHandle": "{œfieldNameœ:œPinecone_callableœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Pinecone_callable",
            "id": "Agent-3OxXM",
            "inputTypes": [
              "Callable"
            ],
            "type": "function"
          },
          "sourceHandle": {
            "dataType": "PineconeSearch",
            "id": "PineconeSearch-XLDaU",
            "name": "Pinecone Callable",
            "output_types": [
              "Callable"
            ]
          }
        },
        "id": "reactflow__edge-PineconeSearch-XLDaU{œdataTypeœ:œPineconeSearchœ,œidœ:œPineconeSearch-XLDaUœ,œnameœ:œPinecone Callableœ,œoutput_typesœ:[œCallableœ]}-Agent-3OxXM{œfieldNameœ:œPinecone_callableœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ProcessImages-jUkrU",
        "sourceHandle": "{œdataTypeœ:œProcessImagesœ,œidœ:œProcessImages-jUkrUœ,œnameœ:œProcess Images Callableœ,œoutput_typesœ:[œCallableœ]}",
        "target": "Agent-3OxXM",
        "targetHandle": "{œfieldNameœ:œImage_callableœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "data": {
          "targetHandle": {
            "fieldName": "Image_callable",
            "id": "Agent-3OxXM",
            "inputTypes": [
              "Callable"
            ],
            "type": "function"
          },
          "sourceHandle": {
            "dataType": "ProcessImages",
            "id": "ProcessImages-jUkrU",
            "name": "Process Images Callable",
            "output_types": [
              "Callable"
            ]
          }
        },
        "id": "reactflow__edge-ProcessImages-jUkrU{œdataTypeœ:œProcessImagesœ,œidœ:œProcessImages-jUkrUœ,œnameœ:œProcess Images Callableœ,œoutput_typesœ:[œCallableœ]}-Agent-3OxXM{œfieldNameœ:œImage_callableœ,œidœ:œAgent-3OxXMœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "StableDiffusion-PjO0G",
        "sourceHandle": "{œdataTypeœ:œStableDiffusionœ,œidœ:œStableDiffusion-PjO0Gœ,œnameœ:œImgGen Callableœ,œoutput_typesœ:[œCallableœ]}",
        "target": "ProcessImages-jUkrU",
        "targetHandle": "{œfieldNameœ:œimggen_callableœ,œidœ:œProcessImages-jUkrUœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "data": {
          "targetHandle": {
            "fieldName": "imggen_callable",
            "id": "ProcessImages-jUkrU",
            "inputTypes": [
              "Callable"
            ],
            "type": "function"
          },
          "sourceHandle": {
            "dataType": "StableDiffusion",
            "id": "StableDiffusion-PjO0G",
            "name": "ImgGen Callable",
            "output_types": [
              "Callable"
            ]
          }
        },
        "id": "reactflow__edge-StableDiffusion-PjO0G{œdataTypeœ:œStableDiffusionœ,œidœ:œStableDiffusion-PjO0Gœ,œnameœ:œImgGen Callableœ,œoutput_typesœ:[œCallableœ]}-ProcessImages-jUkrU{œfieldNameœ:œimggen_callableœ,œidœ:œProcessImages-jUkrUœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "CloudinaryUploader-4IS8Y",
        "sourceHandle": "{œdataTypeœ:œCloudinaryUploaderœ,œidœ:œCloudinaryUploader-4IS8Yœ,œnameœ:œuploader_callableœ,œoutput_typesœ:[œCallableœ]}",
        "target": "ProcessImages-jUkrU",
        "targetHandle": "{œfieldNameœ:œuploader_callableœ,œidœ:œProcessImages-jUkrUœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "data": {
          "targetHandle": {
            "fieldName": "uploader_callable",
            "id": "ProcessImages-jUkrU",
            "inputTypes": [
              "Callable"
            ],
            "type": "function"
          },
          "sourceHandle": {
            "dataType": "CloudinaryUploader",
            "id": "CloudinaryUploader-4IS8Y",
            "name": "uploader_callable",
            "output_types": [
              "Callable"
            ]
          }
        },
        "id": "reactflow__edge-CloudinaryUploader-4IS8Y{œdataTypeœ:œCloudinaryUploaderœ,œidœ:œCloudinaryUploader-4IS8Yœ,œnameœ:œuploader_callableœ,œoutput_typesœ:[œCallableœ]}-ProcessImages-jUkrU{œfieldNameœ:œuploader_callableœ,œidœ:œProcessImages-jUkrUœ,œinputTypesœ:[œCallableœ],œtypeœ:œfunctionœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "Directory-akX5U",
        "sourceHandle": "{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-akX5Uœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "Pinecone-R8c3L",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œPinecone-R8c3Lœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "Pinecone-R8c3L",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Directory",
            "id": "Directory-akX5U",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-Directory-akX5U{œdataTypeœ:œDirectoryœ,œidœ:œDirectory-akX5Uœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-Pinecone-R8c3L{œfieldNameœ:œingest_dataœ,œidœ:œPinecone-R8c3Lœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false
      }
    ],
    "viewport": {
      "x": 1142.9753895239223,
      "y": -418.75836988638116,
      "zoom": 0.47855344289679397
    }
  },
  "description": "Generates Shadcn Tailwind CSS Website",
  "name": "Website Generation New",
  "last_tested_version": "1.1.1",
  "endpoint_name": "new",
  "is_component": false
}